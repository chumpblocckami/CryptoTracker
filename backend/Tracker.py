import requestsfrom apscheduler.schedulers.background import BackgroundSchedulerfrom bs4 import BeautifulSoup as bsimport timefrom elasticsearch import Elasticsearchclass CurrencyTracker():    def __init__(self,                 currency="bitcoin",                 download_time=10):        """        Download information about cryptocurrency price from Coinmarketcap.        :param currency: State the currency to be tracked        :param download_time: Rate of price's download (in seconds)        """        self.currency = currency        self.URL = f"https://coinmarketcap.com/currencies/{currency}/"        self.download_time = download_time  # time is in seconds        self.scheduler = self.init_scheduler()        self.es = Elasticsearch(hosts=["elasticsearch"],                                http_auth=("", ""),                                timeout=40,                                max_retries=10,                                retry_on_timeout=True,)    def init_scheduler(self):        scheduler = BackgroundScheduler()        scheduler.add_job(self.job,                          'interval',                          seconds=self.download_time,                          name=f"{self.currency}_tracker")        return scheduler    def job(self):        r = requests.get(self.URL)        soup = bs(r.content, 'html.parser')        price = soup.find("div", {"class": "priceValue"}).select_one("span").text        price = float(price.replace(",", "").replace("$", "").strip())        timestamp = int(round(time.time() * 1000))        doc = {"price": price,               "timestamp": timestamp}        self.es.index(index=self.currency,                         doc_type="_doc",                         id=timestamp,                         document=doc)        del r, soup, price, doc,timestamp    def start(self):        self.scheduler.start()        print(f"{self.currency} tracker started")